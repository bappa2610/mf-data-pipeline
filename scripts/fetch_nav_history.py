import csv
import requests
import os
import time
from datetime import datetime, date
from concurrent.futures import ThreadPoolExecutor, as_completed

# ================= CONFIG =================
CODES_FILE = "data/scheme_codes.csv"
NAV_DIR = "data/nav_history"

MAX_WORKERS = 8
REQUEST_DELAY = 0.12
CONNECT_TIMEOUT = 2
READ_TIMEOUT = 5

TODAY = date.today().isoformat()
# ==========================================

print("üìÅ Ensuring NAV history directory exists...")
os.makedirs(NAV_DIR, exist_ok=True)


# ---------- ULTRA FAST LAST DATE ----------
def read_last_date(filepath):
    if not os.path.exists(filepath):
        print("   ‚Ü≥ No existing NAV file found")
        return None
    try:
        with open(filepath, "rb") as f:
            f.seek(-256, os.SEEK_END)
            last_line = f.readlines()[-1].decode().strip()
            if last_line and not last_line.startswith("Date"):
                last_date = last_line.split(",")[0]
                print(f"   ‚Ü≥ Last stored NAV date: {last_date}")
                return last_date
    except Exception:
        print("   ‚Ü≥ Could not read last date safely")
    return None


# ---------- WORKER FUNCTION ----------
def process_scheme(args):
    i, total, scheme = args
    code = scheme["SchemeCode"]
    filepath = os.path.join(NAV_DIR, f"{code}.csv")

    print(f"\nüîÑ [{i}/{total}] Processing scheme {code}")

    last_date = read_last_date(filepath)

    # ‚úÖ Skip API call entirely if already up to date
    if last_date == TODAY:
        print("   ‚è≠ Already up to date ‚Äî skipping API call")
        return f"[{i}/{total}] {code} ‚Üí up to date"

    print("   üåê Fetching NAV data from API...")

    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (NAV-Updater)"
    })

    try:
        r = session.get(
            f"https://api.mfapi.in/mf/{code}",
            timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)
        )

        if r.status_code != 200:
            print("   ‚ùå API returned non-200 status")
            return f"[{i}/{total}] {code} ‚Üí API error"

        data = r.json().get("data")
        if not data:
            print("   ‚ö† API returned empty data")
            return f"[{i}/{total}] {code} ‚Üí no data"

        print(f"   üì¶ Total NAV records received: {len(data)}")

        last_date_obj = (
            datetime.fromisoformat(last_date).date()
            if last_date else None
        )

        new_rows = []
        for row in reversed(data):
            nav_date = datetime.strptime(row["date"], "%d-%m-%Y").date()
            if last_date_obj and nav_date <= last_date_obj:
                continue

            new_rows.append({
                "Date": nav_date.isoformat(),
                "NAV": row["nav"]
            })

        print(f"   ‚ûï New NAV rows after date filter: {len(new_rows)}")

        if not new_rows:
            return f"[{i}/{total}] {code} ‚Üí no new NAV"

        # ---------- DUPLICATE PREVENTION ----------
        existing_dates = set()
        if os.path.exists(filepath):
            print("   üîç Checking for duplicate dates...")
            with open(filepath, newline="", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    existing_dates.add(row["Date"])

        new_rows_filtered = [
            row for row in new_rows
            if row["Date"] not in existing_dates
        ]

        print(f"   üßπ Rows after duplicate removal: {len(new_rows_filtered)}")

        if new_rows_filtered:
            write_header = not os.path.exists(filepath)
            print("   üíæ Writing NAV rows to CSV...")
            with open(filepath, "a", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=["Date", "NAV"])
                if write_header:
                    writer.writeheader()
                writer.writerows(new_rows_filtered)

        print("   ‚è± Sleeping briefly to respect API limits...")
        time.sleep(REQUEST_DELAY)

        return f"[{i}/{total}] {code} ‚Üí +{len(new_rows_filtered)} rows"

    except requests.exceptions.RequestException:
        print("   üö´ Network error occurred")
        return f"[{i}/{total}] {code} ‚Üí network error"
    except Exception as e:
        print(f"   ‚ùå Unexpected error: {e}")
        return f"[{i}/{total}] {code} ‚Üí error: {e}"


# ---------- LOAD SCHEME CODES ----------
print("\nüìÑ Loading scheme codes...")
with open(CODES_FILE, newline="", encoding="utf-8") as f:
    schemes = list(csv.DictReader(f))

total = len(schemes)
print(f"üìä Total schemes loaded: {total}")
print(f"‚öôÔ∏è Parallel workers: {MAX_WORKERS}\n")

tasks = [(i, total, scheme) for i, scheme in enumerate(schemes, start=1)]

# ---------- PARALLEL EXECUTION ----------
print("üöÄ Starting NAV update process...\n")

with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
    futures = [executor.submit(process_scheme, t) for t in tasks]
    for future in as_completed(futures):
        print("‚úÖ", future.result())

print("\nüéâ NAV history update completed successfully")
